{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING VIET OCR TO RECOGNIZE TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from vietocr.tool.predictor import Predictor\n",
    "from vietocr.tool.config import Cfg\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kh·ªüi t·∫°o PaddleOCR v√† VietOCR\n",
    "# ocr = PaddleOCR(lang='vi')\n",
    "#Viet OCR\n",
    "cfg = Cfg.load_config_from_name('vgg_transformer')\n",
    "predictor = Predictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'D:\\Private\\Project\\kaggle\\OCR\\PaddleOCR\\data_OCR\\final_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# files = sorted(os.listdir(folder_path))\n",
    "\n",
    "# for index, file in enumerate(files, start=1):\n",
    "#     old_path = os.path.join(folder_path, file)\n",
    "#     new_name = f\"img_{index}.jpg\" \n",
    "#     new_path = os.path.join(folder_path, new_name)\n",
    "\n",
    "#     os.rename(old_path, new_path)\n",
    "\n",
    "# print(\"ƒê·ªïi t√™n th√†nh c√¥ng!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "label_folder = r'D:\\Private\\Project\\kaggle\\OCR\\PaddleOCR\\data_OCR\\labels' \n",
    "\n",
    "os.makedirs(label_folder, exist_ok=True)\n",
    "\n",
    "def create_labels(folder_path):\n",
    "    folder_path = os.path.abspath(folder_path)  # Chuy·ªÉn th√†nh ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi\n",
    "    for path in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, path)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "            # D·ª± ƒëo√°n vƒÉn b·∫£n trong ·∫£nh\n",
    "            text = predictor.predict(image)\n",
    "\n",
    "            # Chuy·ªÉn ƒë∆∞·ªùng d·∫´n ·∫£nh sang t∆∞∆°ng ƒë·ªëi (gi·ªØ nguy√™n d·∫•u `\\` tr√™n Windows)\n",
    "            relative_image_path = os.path.relpath(image_path, os.getcwd())\n",
    "\n",
    "            # L∆∞u nh√£n\n",
    "            label_file_path = os.path.join(label_folder, f\"{os.path.splitext(path)[0]}.txt\")\n",
    "            with open(label_file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"{relative_image_path}\\t{text}\\n\")\n",
    "\n",
    "            print(f\"‚úÖ ƒê√£ l∆∞u nh√£n cho ·∫£nh {path} v√†o {label_file_path}\")\n",
    "            print(f\"- N·ªôi dung: {text}\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå L·ªói khi x·ª≠ l√Ω ·∫£nh {path}: {e}\")\n",
    "\n",
    "\n",
    "create_labels(folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERGE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def merge_txt_files(folder_path, output_file):\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        # Duy·ªát t·∫•t c·∫£ c√°c file trong th∆∞ m·ª•c\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            # Ch·ªâ x·ª≠ l√Ω file .txt\n",
    "            if file_name.endswith(\".txt\") and os.path.isfile(file_path):\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f_in:\n",
    "                    # Ghi n·ªôi dung file v√†o file g·ªôp\n",
    "                    f_out.write(f_in.read())\n",
    "\n",
    "    print(f\"‚úÖ Merged all .txt files into: {output_file}\")\n",
    "\n",
    "# V√≠ d·ª• s·ª≠ d·ª•ng\n",
    "training_folder = r\"D:\\Private\\Project\\kaggle\\OCR\\PaddleOCR\\data_OCR\\labels\"\n",
    "output_file = (r\"D:\\Private\\Project\\kaggle\\OCR\\PaddleOCR\\dataset\\train_labels.txt\")\n",
    "\n",
    "merge_txt_files(training_folder, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn c√°c th∆∞ m·ª•c\n",
    "train_images_dir = r\"D:\\Private\\Project\\kaggle\\OCR\\PaddleOCR\\data_OCR\\final_data\"  # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø\n",
    "labels_dir = r\"D:\\Private\\Project\\kaggle\\OCR\\PaddleOCR\\data_OCR\\labels\"              # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø\n",
    "\n",
    "# ƒê·∫£m b·∫£o c√°c th∆∞ m·ª•c t·ªìn t·∫°i\n",
    "if not os.path.exists(train_images_dir):\n",
    "    print(f\"Th∆∞ m·ª•c {train_images_dir} kh√¥ng t·ªìn t·∫°i!\")\n",
    "    exit()\n",
    "if not os.path.exists(labels_dir):\n",
    "    print(f\"Th∆∞ m·ª•c {labels_dir} kh√¥ng t·ªìn t·∫°i!\")\n",
    "    exit()\n",
    "\n",
    "# L·∫•y danh s√°ch t√™n file trong train_images (ch·ªâ l·∫•y t√™n c∆° b·∫£n, b·ªè ph·∫ßn m·ªü r·ªông)\n",
    "image_files = set()\n",
    "for image_file in os.listdir(train_images_dir):\n",
    "    if image_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):  # H·ªó tr·ª£ nhi·ªÅu ƒë·ªãnh d·∫°ng\n",
    "        image_name = os.path.splitext(image_file)[0].lower()  # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng ƒë·ªÉ so s√°nh\n",
    "        image_files.add(image_name)\n",
    "\n",
    "# L·∫•y danh s√°ch t√™n file trong labels (ch·ªâ l·∫•y t√™n c∆° b·∫£n, b·ªè ph·∫ßn m·ªü r·ªông)\n",
    "label_files = set()\n",
    "for label_file in os.listdir(labels_dir):\n",
    "    if label_file.lower().endswith(\".txt\"):\n",
    "        label_name = os.path.splitext(label_file)[0].lower()  # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng ƒë·ªÉ so s√°nh\n",
    "        label_files.add(label_name)\n",
    "\n",
    "# Ki·ªÉm tra s·ª± t∆∞∆°ng ·ª©ng\n",
    "missing_images = label_files - image_files  # C√°c label kh√¥ng c√≥ ·∫£nh t∆∞∆°ng ·ª©ng\n",
    "extra_images = image_files - label_files    # C√°c ·∫£nh kh√¥ng c√≥ label t∆∞∆°ng ·ª©ng\n",
    "\n",
    "# B√°o c√°o k·∫øt qu·∫£\n",
    "if missing_images:\n",
    "    print(\"C√°c file label kh√¥ng c√≥ ·∫£nh t∆∞∆°ng ·ª©ng:\")\n",
    "    for name in missing_images:\n",
    "        print(f\"- {name}.txt (kh√¥ng c√≥ {name}.jpg)\")\n",
    "else:\n",
    "    print(\"T·∫•t c·∫£ file label ƒë·ªÅu c√≥ ·∫£nh t∆∞∆°ng ·ª©ng.\")\n",
    "\n",
    "if extra_images:\n",
    "    print(\"C√°c file ·∫£nh kh√¥ng c√≥ label t∆∞∆°ng ·ª©ng:\")\n",
    "    for name in extra_images:\n",
    "        print(f\"- {name}.jpg (kh√¥ng c√≥ {name}.txt)\")\n",
    "else:\n",
    "    print(\"T·∫•t c·∫£ file ·∫£nh ƒë·ªÅu c√≥ label t∆∞∆°ng ·ª©ng.\")\n",
    "\n",
    "# T√πy ch·ªçn: In danh s√°ch ƒë"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c v√† file\n",
    "data_dir = \"train_data/ic15_data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "eval_dir = os.path.join(data_dir, \"eval\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# ƒê·ªçc file train_labels.txt\n",
    "label_file = \"D:/Private/Project/kaggle/OCR/PaddleOCR/dataset/train_labels.txt\"\n",
    "with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# T√°ch ƒë∆∞·ªùng d·∫´n ·∫£nh v√† nh√£n\n",
    "image_paths = []\n",
    "labels = []\n",
    "for line in lines:\n",
    "    image_path, label = line.strip().split(\"\\t\")\n",
    "    image_paths.append(image_path)\n",
    "    labels.append(label)\n",
    "\n",
    "# T√°ch d·ªØ li·ªáu th√†nh train (80%), eval (10%), test (10%)\n",
    "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "eval_paths, test_paths, eval_labels, test_labels = train_test_split(\n",
    "    temp_paths, temp_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# H√†m di chuy·ªÉn ·∫£nh v√† t·∫°o file nh√£n\n",
    "def move_images_and_create_labels(image_paths, labels, target_dir, label_file):\n",
    "    with open(label_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for img_path, label in zip(image_paths, labels):\n",
    "            # T√™n file ·∫£nh\n",
    "            img_name = os.path.basename(img_path)\n",
    "            # ƒê∆∞·ªùng d·∫´n m·ªõi\n",
    "            new_img_path = os.path.join(target_dir, img_name)\n",
    "            # Di chuy·ªÉn ·∫£nh\n",
    "            shutil.copy(img_path, new_img_path)\n",
    "            # Ghi v√†o file nh√£n\n",
    "            rel_path = os.path.join(os.path.basename(target_dir), img_name)\n",
    "            f.write(f\"{rel_path}\\t{label}\\n\")\n",
    "\n",
    "# T·∫°o c√°c t·∫≠p d·ªØ li·ªáu\n",
    "move_images_and_create_labels(train_paths, train_labels, train_dir, os.path.join(data_dir, \"rec_gt_train.txt\"))\n",
    "move_images_and_create_labels(eval_paths, eval_labels, eval_dir, os.path.join(data_dir, \"rec_gt_eval.txt\"))\n",
    "move_images_and_create_labels(test_paths, test_labels, test_dir, os.path.join(data_dir, \"rec_gt_test.txt\"))\n",
    "\n",
    "print(\"D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t√°ch th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Th∆∞ m·ª•c d·ªØ li·ªáu\n",
    "base_dir = \"D:/Private/Project/kaggle/OCR/PaddleOCR\"\n",
    "data_dir = os.path.join(base_dir, \"train_data/ic15_data\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "eval_dir = os.path.join(data_dir, \"eval\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "for folder in [train_dir, eval_dir, test_dir]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# File nh√£n v√† th∆∞ m·ª•c ·∫£nh\n",
    "label_file = os.path.join(base_dir, \"dataset/train_labels.txt\")\n",
    "drive_dir = os.path.join(base_dir, \"data_OCR/final_data\")\n",
    "\n",
    "if not os.path.exists(label_file):\n",
    "    raise FileNotFoundError(f\"File nh√£n kh√¥ng t·ªìn t·∫°i: {label_file}\")\n",
    "\n",
    "# ƒê·ªçc file nh√£n\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        try:\n",
    "            image_path, label = line.strip().split(\"\\t\")\n",
    "            abs_image_path = os.path.abspath(os.path.join(base_dir, image_path)).replace(\"\\\\\", \"/\")\n",
    "\n",
    "            if os.path.exists(abs_image_path):\n",
    "                image_paths.append(abs_image_path)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                print(f\"C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y ·∫£nh - {abs_image_path}\")\n",
    "        except ValueError:\n",
    "            print(f\"B·ªè qua d√≤ng l·ªói ƒë·ªãnh d·∫°ng: {line.strip()}\")\n",
    "\n",
    "if not image_paths:\n",
    "    raise ValueError(\"Kh√¥ng c√≥ ·∫£nh h·ª£p l·ªá trong danh s√°ch!\")\n",
    "\n",
    "# Chia t·∫≠p d·ªØ li·ªáu\n",
    "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "eval_paths, test_paths, eval_labels, test_labels = train_test_split(\n",
    "    temp_paths, temp_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# H√†m di chuy·ªÉn ·∫£nh v√† t·∫°o file nh√£n\n",
    "def move_images_and_create_labels(image_paths, labels, target_dir, label_file):\n",
    "    with open(label_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for img_path, label in zip(image_paths, labels):\n",
    "            try:\n",
    "                img_name = os.path.basename(img_path)\n",
    "                new_img_path = os.path.join(target_dir, img_name)\n",
    "\n",
    "                shutil.copy(img_path, new_img_path)\n",
    "                abs_path = os.path.abspath(new_img_path).replace(\"\\\\\", \"/\")\n",
    "\n",
    "                f.write(f\"{abs_path}\\t{label}\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"L·ªói khi di chuy·ªÉn ·∫£nh {img_path}: {e}\")\n",
    "\n",
    "# Di chuy·ªÉn ·∫£nh v√† t·∫°o file nh√£n\n",
    "move_images_and_create_labels(train_paths, train_labels, train_dir, os.path.join(data_dir, \"rec_gt_train.txt\"))\n",
    "move_images_and_create_labels(eval_paths, eval_labels, eval_dir, os.path.join(data_dir, \"rec_gt_eval.txt\"))\n",
    "move_images_and_create_labels(test_paths, test_labels, test_dir, os.path.join(data_dir, \"rec_gt_test.txt\"))\n",
    "\n",
    "# Th·ªëng k√™ k·∫øt qu·∫£\n",
    "print(\"D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t√°ch th√†nh c√¥ng!\")\n",
    "print(f\"S·ªë l∆∞·ª£ng ·∫£nh train: {len(train_paths)}\")\n",
    "print(f\"S·ªë l∆∞·ª£ng ·∫£nh eval: {len(eval_paths)}\")\n",
    "print(f\"S·ªë l∆∞·ª£ng ·∫£nh test: {len(test_paths)}\")\n",
    "\n",
    "for folder, name in zip([train_dir, eval_dir, test_dir], [\"train\", \"eval\", \"test\"]):\n",
    "    print(f\"Th∆∞ m·ª•c {name}: {folder}, c√≥ {len(os.listdir(folder))} ·∫£nh\")\n",
    "\n",
    "print(\"Th∆∞ m·ª•c l√†m vi·ªác hi·ªán t·∫°i:\", os.getcwd())\n",
    "\n",
    "# Ki·ªÉm tra th·ª≠ m·ªôt ·∫£nh\n",
    "check_img = os.path.join(train_dir, \"img_280.jpg\")\n",
    "check_img = os.path.abspath(check_img).replace(\"\\\\\", \"/\")\n",
    "if os.path.exists(check_img):\n",
    "    print(f\"·∫¢nh t·ªìn t·∫°i: {check_img}\")\n",
    "else:\n",
    "    print(f\"·∫¢nh kh√¥ng t·ªìn t·∫°i: {check_img}\")\n",
    "\n",
    "# M√£ ƒë√£ t·ªëi ∆∞u v√† s·∫µn s√†ng ch·∫°y üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c g·ªëc (tuy·ªát ƒë·ªëi)\n",
    "# data_dir = r\"D:\\Private\\Project\\kaggle\\OCR\\PaddleOCR\\train_data\\ic15_data\"\n",
    "# os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# # ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi cho c√°c th∆∞ m·ª•c train, eval, test\n",
    "# train_dir = os.path.join(data_dir, \"train\")\n",
    "# eval_dir = os.path.join(data_dir, \"eval\")\n",
    "# test_dir = os.path.join(data_dir, \"test\")\n",
    "# os.makedirs(train_dir, exist_ok=True)\n",
    "# os.makedirs(eval_dir, exist_ok=True)\n",
    "# os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# # ƒê·ªçc file train_labels.txt\n",
    "# label_file = r\"D:\\Private\\Project\\kaggle\\OCR\\PaddleOCR\\dataset\\train_labels.txt\"\n",
    "# with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "#     lines = f.readlines()\n",
    "\n",
    "# # T√°ch ƒë∆∞·ªùng d·∫´n ·∫£nh v√† nh√£n\n",
    "# image_paths = []\n",
    "# labels = []\n",
    "# for line in lines:\n",
    "#     image_path, label = line.strip().split(\"\\t\")\n",
    "#     image_paths.append(image_path)\n",
    "#     labels.append(label)\n",
    "\n",
    "# # T√°ch d·ªØ li·ªáu th√†nh train (80%), eval (10%), test (10%)\n",
    "# train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
    "#     image_paths, labels, test_size=0.2, random_state=42\n",
    "# )\n",
    "# eval_paths, test_paths, eval_labels, test_labels = train_test_split(\n",
    "#     temp_paths, temp_labels, test_size=0.5, random_state=42\n",
    "# )\n",
    "\n",
    "# # H√†m di chuy·ªÉn ·∫£nh v√† t·∫°o file nh√£n v·ªõi ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi\n",
    "# def move_images_and_create_labels(image_paths, labels, target_dir, label_file):\n",
    "#     with open(label_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#         for img_path, label in zip(image_paths, labels):\n",
    "#             # T√™n file ·∫£nh\n",
    "#             img_name = os.path.basename(img_path)\n",
    "#             # ƒê∆∞·ªùng d·∫´n m·ªõi (tuy·ªát ƒë·ªëi)\n",
    "#             new_img_path = os.path.join(target_dir, img_name)\n",
    "#             # Di chuy·ªÉn ·∫£nh\n",
    "#             shutil.copy(img_path, new_img_path)\n",
    "#             Ghi ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi v√†o file nh√£n\n",
    "#             abs_path = os.path.abspath(new_img_path)  # L·∫•y ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi\n",
    "#             # Thay d·∫•u \\ th√†nh / ƒë·ªÉ ƒë·ªìng b·ªô tr√™n c√°c h·ªá ƒëi·ªÅu h√†nh\n",
    "#             abs_path = abs_path.replace(\"\\\\\", \"/\")\n",
    "#             f.write(f\"{abs_path}\\t{label}\\n\")\n",
    "\n",
    "# # T·∫°o c√°c t·∫≠p d·ªØ li·ªáu\n",
    "# move_images_and_create_labels(\n",
    "#     train_paths, train_labels, train_dir, os.path.join(data_dir, \"rec_gt_train.txt\")\n",
    "# )\n",
    "# move_images_and_create_labels(\n",
    "#     eval_paths, eval_labels, eval_dir, os.path.join(data_dir, \"rec_gt_eval.txt\")\n",
    "# )\n",
    "# move_images_and_create_labels(\n",
    "#     test_paths, test_labels, test_dir, os.path.join(data_dir, \"rec_gt_test.txt\")\n",
    "# )\n",
    "\n",
    "# print(\"D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t√°ch th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a c√°c file nh√£n\n",
    "data_dir = r\"D:\\Private\\Project\\kaggle\\OCR\\PaddleOCR\\train_data\\ic15_data\"\n",
    "\n",
    "# Danh s√°ch c√°c file nh√£n c·∫ßn ki·ªÉm tra\n",
    "label_files = [\n",
    "    os.path.join(data_dir, \"rec_gt_train.txt\"),\n",
    "    os.path.join(data_dir, \"rec_gt_eval.txt\"),\n",
    "    os.path.join(data_dir, \"rec_gt_test.txt\")\n",
    "]\n",
    "\n",
    "# H√†m ki·ªÉm tra ƒë∆∞·ªùng d·∫´n trong file nh√£n\n",
    "def check_image_paths(label_file):\n",
    "    if not os.path.exists(label_file):\n",
    "        print(f\"File nh√£n {label_file} kh√¥ng t·ªìn t·∫°i!\")\n",
    "        return\n",
    "\n",
    "    with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    print(f\"\\nKi·ªÉm tra file nh√£n: {label_file}\")\n",
    "    missing_images = 0\n",
    "    for line in lines:\n",
    "        try:\n",
    "            # T√°ch ƒë∆∞·ªùng d·∫´n v√† nh√£n\n",
    "            img_path, label = line.strip().split(\"\\t\")\n",
    "            # Ki·ªÉm tra xem ƒë∆∞·ªùng d·∫´n c√≥ t·ªìn t·∫°i kh√¥ng\n",
    "            if not os.path.exists(img_path):\n",
    "                print(f\"·∫¢nh kh√¥ng t·ªìn t·∫°i: {img_path}\")\n",
    "                missing_images += 1\n",
    "            else:\n",
    "                print(f\"·∫¢nh t·ªìn t·∫°i: {img_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"L·ªói khi x·ª≠ l√Ω d√≤ng: {line.strip()} - L·ªói: {e}\")\n",
    "            missing_images += 1\n",
    "\n",
    "    if missing_images == 0:\n",
    "        print(f\"T·∫•t c·∫£ ·∫£nh trong {label_file} ƒë·ªÅu t·ªìn t·∫°i!\")\n",
    "    else:\n",
    "        print(f\"T·ªïng s·ªë ·∫£nh kh√¥ng t·ªìn t·∫°i: {missing_images}\")\n",
    "\n",
    "# Ki·ªÉm tra t·ª´ng file nh√£n\n",
    "for label_file in label_files:\n",
    "    check_image_paths(label_file)\n",
    "\n",
    "print(\"\\nKi·ªÉm tra ho√†n t·∫•t!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def check_dataset(label_file, base_dir):\n",
    "    with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    valid_lines = []\n",
    "    for line in lines:\n",
    "        try:\n",
    "            img_path, label = line.strip().split(\"\\t\")\n",
    "            full_path = os.path.join(base_dir, img_path)\n",
    "            if os.path.exists(full_path):\n",
    "                valid_lines.append(line)\n",
    "            else:\n",
    "                print(f\"Kh√¥ng t√¨m th·∫•y ·∫£nh: {full_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"L·ªói ·ªü d√≤ng: {line.strip()} - {e}\")\n",
    "\n",
    "    # Ghi l·∫°i file nh√£n ƒë√£ l√†m s·∫°ch\n",
    "    with open(label_file + \".clean\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(valid_lines)\n",
    "\n",
    "# Ki·ªÉm tra c·∫£ train v√† eval\n",
    "base_dir = \"./train_data/ic15_data\"\n",
    "check_dataset(\"train_data/ic15_data/rec_gt_train.txt\", base_dir)\n",
    "check_dataset(\"train_data/ic15_data/rec_gt_eval.txt\", base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn c√°c th∆∞ m·ª•c\n",
    "train_images_dir = r\"D:\\Private\\Project\\kaggle\\OCR\\PaddleOCR\\dataset\\train_images\"  # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø\n",
    "labels_dir = \"./labels\"              # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø\n",
    "\n",
    "# ƒê·∫£m b·∫£o c√°c th∆∞ m·ª•c t·ªìn t·∫°i\n",
    "if not os.path.exists(train_images_dir):\n",
    "    print(f\"Th∆∞ m·ª•c {train_images_dir} kh√¥ng t·ªìn t·∫°i!\")\n",
    "    exit()\n",
    "if not os.path.exists(labels_dir):\n",
    "    print(f\"Th∆∞ m·ª•c {labels_dir} kh√¥ng t·ªìn t·∫°i!\")\n",
    "    exit()\n",
    "\n",
    "# L·∫∑p qua t·∫•t c·∫£ file trong th∆∞ m·ª•c labels\n",
    "for label_file in os.listdir(labels_dir):\n",
    "    if label_file.endswith(\".txt\"):\n",
    "        label_path = os.path.join(labels_dir, label_file)\n",
    "        \n",
    "        # Ki·ªÉm tra file r·ªóng\n",
    "        if os.path.getsize(label_path) == 0:\n",
    "            print(f\"File r·ªóng: {label_path}\")\n",
    "            \n",
    "            # L·∫•y t√™n file ·∫£nh t∆∞∆°ng ·ª©ng (thay .txt b·∫±ng .jpg)\n",
    "            image_name = os.path.splitext(label_file)[0] + \".jpg\"\n",
    "            image_path = os.path.join(train_images_dir, image_name)\n",
    "            \n",
    "            # X√≥a file nh√£n r·ªóng\n",
    "            os.remove(label_path)\n",
    "            print(f\"ƒê√£ x√≥a file nh√£n: {label_path}\")\n",
    "            \n",
    "            # X√≥a ·∫£nh t∆∞∆°ng ·ª©ng n·∫øu t·ªìn t·∫°i\n",
    "            if os.path.exists(image_path):\n",
    "                os.remove(image_path)\n",
    "                print(f\"ƒê√£ x√≥a ·∫£nh: {image_path}\")\n",
    "            else:\n",
    "                print(f\"Kh√¥ng t√¨m th·∫•y ·∫£nh t∆∞∆°ng ·ª©ng: {image_path}\")\n",
    "        else:\n",
    "            print(f\"File {label_path} kh√¥ng r·ªóng, b·ªè qua.\")\n",
    "\n",
    "print(\"Ki·ªÉm tra v√† x√≥a ho√†n t·∫•t!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn c√°c th∆∞ m·ª•c\n",
    "# train_images_dir = train_images_dir # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø\n",
    "# labels_dir = \"labels\"              # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø\n",
    "\n",
    "# ƒê·∫£m b·∫£o c√°c th∆∞ m·ª•c t·ªìn t·∫°i\n",
    "if not os.path.exists(train_images_dir):\n",
    "    print(f\"Th∆∞ m·ª•c {train_images_dir} kh√¥ng t·ªìn t·∫°i!\")\n",
    "    exit()\n",
    "if not os.path.exists(labels_dir):\n",
    "    print(f\"Th∆∞ m·ª•c {labels_dir} kh√¥ng t·ªìn t·∫°i!\")\n",
    "    exit()\n",
    "\n",
    "# L·∫•y danh s√°ch t√™n file trong train_images (ch·ªâ l·∫•y t√™n c∆° b·∫£n, b·ªè ph·∫ßn m·ªü r·ªông)\n",
    "image_files = set()\n",
    "for image_file in os.listdir(train_images_dir):\n",
    "    if image_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):  # H·ªó tr·ª£ nhi·ªÅu ƒë·ªãnh d·∫°ng\n",
    "        image_name = os.path.splitext(image_file)[0].lower()  # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng ƒë·ªÉ so s√°nh\n",
    "        image_files.add(image_name)\n",
    "\n",
    "# L·∫•y danh s√°ch t√™n file trong labels (ch·ªâ l·∫•y t√™n c∆° b·∫£n, b·ªè ph·∫ßn m·ªü r·ªông)\n",
    "label_files = set()\n",
    "for label_file in os.listdir(labels_dir):\n",
    "    if label_file.lower().endswith(\".txt\"):\n",
    "        label_name = os.path.splitext(label_file)[0].lower()  # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng ƒë·ªÉ so s√°nh\n",
    "        label_files.add(label_name)\n",
    "\n",
    "# Ki·ªÉm tra s·ª± t∆∞∆°ng ·ª©ng\n",
    "missing_images = label_files - image_files  # C√°c label kh√¥ng c√≥ ·∫£nh t∆∞∆°ng ·ª©ng\n",
    "extra_images = image_files - label_files    # C√°c ·∫£nh kh√¥ng c√≥ label t∆∞∆°ng ·ª©ng\n",
    "\n",
    "# B√°o c√°o k·∫øt qu·∫£\n",
    "if missing_images:\n",
    "    print(\"C√°c file label kh√¥ng c√≥ ·∫£nh t∆∞∆°ng ·ª©ng:\")\n",
    "    for name in missing_images:\n",
    "        print(f\"- {name}.txt (kh√¥ng c√≥ {name}.jpg)\")\n",
    "else:\n",
    "    print(\"T·∫•t c·∫£ file label ƒë·ªÅu c√≥ ·∫£nh t∆∞∆°ng ·ª©ng.\")\n",
    "\n",
    "if extra_images:\n",
    "    print(\"C√°c file ·∫£nh kh√¥ng c√≥ label t∆∞∆°ng ·ª©ng:\")\n",
    "    for name in extra_images:\n",
    "        print(f\"- {name}.jpg (kh√¥ng c√≥ {name}.txt)\")\n",
    "else:\n",
    "    print(\"T·∫•t c·∫£ file ·∫£nh ƒë·ªÅu c√≥ label t∆∞∆°ng ·ª©ng.\")\n",
    "\n",
    "# T√πy ch·ªçn: In danh s√°ch ƒë·∫ßy ƒë·ªß ƒë·ªÉ ki·ªÉm tra\n",
    "print(\"\\nDanh s√°ch file ·∫£nh:\", sorted(image_files))\n",
    "print(\"Danh s√°ch file label:\", sorted(label_files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete!\n"
     ]
    }
   ],
   "source": [
    "# curl -o pretrain/en_PP-OCRv3_rec_train.tar https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_rec_train.tar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "if paddle.device.is_compiled_with_cuda():\n",
    "    print(\"GPU Name:\", paddle.device.cuda.get_device_name(0))\n",
    "    print(\"Current CUDA Device ID:\", paddle.device.cuda.current_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"cuDNN Available:\", torch.backends.cudnn.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c b·∫°n mu·ªën ƒë·∫øm\n",
    "folder_path = r\"D:\\Private\\Project\\kaggle\\OCR\\PaddleOCR\\data_OCR\\labels\"  # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø, v√≠ d·ª•: \"C:/Users/YourName/Documents\"\n",
    "\n",
    "# ƒê·∫øm s·ªë l∆∞·ª£ng file\n",
    "file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "\n",
    "print(f\"S·ªë l∆∞·ª£ng file trong th∆∞ m·ª•c: {file_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# D·ªØ li·ªáu l·ªãch tr√¨nh t·ª´ bi·ªÉu ƒë·ªì Gantt\n",
    "schedule = [\n",
    "    # (machine, job, operation, start_time, duration)\n",
    "    (0, 1, 0, 0, 2),  # Machine 0: Job 1, operation 0\n",
    "    (0, 0, 0, 2, 3),  # Machine 0: Job 0, operation 0\n",
    "    (1, 2, 0, 0, 4),  # Machine 1: Job 2, operation 0\n",
    "    (1, 1, 2, 4, 4),  # Machine 1: Job 1, operation 2\n",
    "    (1, 0, 1, 8, 2),  # Machine 1: Job 0, operation 1\n",
    "    (2, 1, 1, 2, 1),  # Machine 2: Job 1, operation 1\n",
    "    (2, 2, 1, 4, 3),  # Machine 2: Job 2, operation 1\n",
    "    (2, 0, 2, 10, 2), # Machine 2: Job 0, operation 2\n",
    "]\n",
    "\n",
    "# M√†u s·∫Øc cho t·ª´ng job\n",
    "colors = {0: 'blue', 1: 'red', 2: 'green'}\n",
    "\n",
    "# T·∫°o bi·ªÉu ƒë·ªì Gantt\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "\n",
    "for task in schedule:\n",
    "    machine, job, operation, start, duration = task\n",
    "    ax.broken_barh([(start, duration)], (machine - 0.4, 0.8), facecolors=colors[job], edgecolors='black')\n",
    "    ax.text(start + duration / 2, machine, f'job({job},{operation})', ha='center', va='center', color='white')\n",
    "\n",
    "# C·∫•u h√¨nh tr·ª•c\n",
    "ax.set_yticks(range(3))\n",
    "ax.set_yticklabels(['Machine 0', 'Machine 1', 'Machine 2'])\n",
    "ax.set_xticks(range(13))\n",
    "ax.set_xlabel('Time')\n",
    "ax.grid(True, axis='x')\n",
    "\n",
    "plt.title('Gantt Chart for Job Shop Scheduling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.sat.python import cp_model\n",
    "\n",
    "def solve_job_shop():\n",
    "    # T·∫°o model\n",
    "    model = cp_model.CpModel()\n",
    "\n",
    "    # D·ªØ li·ªáu v√≠ d·ª•: [job_id, task_id, machine_id, duration]\n",
    "    jobs_data = [\n",
    "        [(0, 0, 0, 3), (0, 1, 1, 2), (0, 2, 2, 2)],  # Job 0\n",
    "        [(1, 0, 1, 2), (1, 1, 2, 1), (1, 2, 0, 4)],  # Job 1\n",
    "        [(2, 0, 2, 4), (2, 1, 0, 1), (2, 2, 1, 3)]   # Job 2\n",
    "    ]\n",
    "\n",
    "    machines_count = 3\n",
    "    all_machines = range(machines_count)\n",
    "    jobs_count = len(jobs_data)\n",
    "    all_jobs = range(jobs_count)\n",
    "\n",
    "    # T√≠nh horizon (t·ªïng th·ªùi gian t·ªëi ƒëa)\n",
    "    horizon = sum(task[3] for job in jobs_data for task in job)\n",
    "\n",
    "    # T·∫°o bi·∫øn\n",
    "    task_vars = {}\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id, task in enumerate(job):\n",
    "            _, _, machine, duration = task\n",
    "            suffix = f'_{job_id}_{task_id}'\n",
    "            start_var = model.NewIntVar(0, horizon, 'start' + suffix)\n",
    "            end_var = model.NewIntVar(0, horizon, 'end' + suffix)\n",
    "            interval_var = model.NewIntervalVar(start_var, duration, end_var,\n",
    "                                              'interval' + suffix)\n",
    "            task_vars[(job_id, task_id)] = (start_var, end_var, interval_var, machine)\n",
    "\n",
    "    # Th√™m r√†ng bu·ªôc th·ª© t·ª± cho c√°c task trong m·ªói job\n",
    "    for job_id in all_jobs:\n",
    "        for task_id in range(len(jobs_data[job_id]) - 1):\n",
    "            model.Add(task_vars[(job_id, task_id)][1] <= \n",
    "                     task_vars[(job_id, task_id + 1)][0])\n",
    "\n",
    "    # R√†ng bu·ªôc kh√¥ng overlap tr√™n t·ª´ng m√°y\n",
    "    machine_to_intervals = {machine: [] for machine in all_machines}\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id, task in enumerate(job):\n",
    "            machine = task[2]\n",
    "            machine_to_intervals[machine].append(task_vars[(job_id, task_id)][2])\n",
    "\n",
    "    for machine in all_machines:\n",
    "        model.AddNoOverlap(machine_to_intervals[machine])\n",
    "\n",
    "    # H√†m m·ª•c ti√™u: t·ªëi thi·ªÉu makespan\n",
    "    makespan = model.NewIntVar(0, horizon, 'makespan')\n",
    "    for job_id in all_jobs:\n",
    "        last_task_id = len(jobs_data[job_id]) - 1\n",
    "        model.Add(makespan >= task_vars[(job_id, last_task_id)][1])\n",
    "    model.Minimize(makespan)\n",
    "\n",
    "    # Gi·∫£i b√†i to√°n\n",
    "    solver = cp_model.CpSolver()\n",
    "    status = solver.Solve(model)\n",
    "\n",
    "    # In k·∫øt qu·∫£\n",
    "    if status == cp_model.OPTIMAL or status == cp_model.FEASIBLE:\n",
    "        print(f'T·ªïng th·ªùi gian ho√†n th√†nh t·ªëi ∆∞u: {solver.Value(makespan)}')\n",
    "        for job_id in all_jobs:\n",
    "            print(f'Job {job_id}:')\n",
    "            for task_id in range(len(jobs_data[job_id])):\n",
    "                start = solver.Value(task_vars[(job_id, task_id)][0])\n",
    "                duration = jobs_data[job_id][task_id][3]\n",
    "                machine = jobs_data[job_id][task_id][2]\n",
    "                print(f'  Task {task_id}: Machine {machine}, Start {start}, Duration {duration}')\n",
    "    else:\n",
    "        print('Kh√¥ng t√¨m th·∫•y gi·∫£i ph√°p.')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    solve_job_shop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.sat.python import cp_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def solve_and_plot_job_shop():\n",
    "    # T·∫°o model\n",
    "    model = cp_model.CpModel()\n",
    "\n",
    "    # D·ªØ li·ªáu v√≠ d·ª•: [job_id, task_id, machine_id, duration]\n",
    "    jobs_data = [\n",
    "        [(0, 0, 0, 3), (0, 1, 1, 2), (0, 2, 2, 2)],  # Job 0\n",
    "        [(1, 0, 1, 2), (1, 1, 2, 1), (1, 2, 0, 4)],  # Job 1\n",
    "        [(2, 0, 2, 4), (2, 1, 0, 1), (2, 2, 1, 3)]   # Job 2\n",
    "    ]\n",
    "\n",
    "    machines_count = 3\n",
    "    all_machines = range(machines_count)\n",
    "    jobs_count = len(jobs_data)\n",
    "    all_jobs = range(jobs_count)\n",
    "\n",
    "    # T√≠nh horizon\n",
    "    horizon = sum(task[3] for job in jobs_data for task in job)\n",
    "\n",
    "    # T·∫°o bi·∫øn\n",
    "    task_vars = {}\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id, task in enumerate(job):\n",
    "            _, _, machine, duration = task\n",
    "            suffix = f'_{job_id}_{task_id}'\n",
    "            start_var = model.NewIntVar(0, horizon, 'start' + suffix)\n",
    "            end_var = model.NewIntVar(0, horizon, 'end' + suffix)\n",
    "            interval_var = model.NewIntervalVar(start_var, duration, end_var,\n",
    "                                              'interval' + suffix)\n",
    "            task_vars[(job_id, task_id)] = (start_var, end_var, interval_var, machine)\n",
    "\n",
    "    # R√†ng bu·ªôc th·ª© t·ª± task trong job\n",
    "    for job_id in all_jobs:\n",
    "        for task_id in range(len(jobs_data[job_id]) - 1):\n",
    "            model.Add(task_vars[(job_id, task_id)][1] <= \n",
    "                     task_vars[(job_id, task_id + 1)][0])\n",
    "\n",
    "    # R√†ng bu·ªôc kh√¥ng overlap tr√™n m√°y\n",
    "    machine_to_intervals = {machine: [] for machine in all_machines}\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id, task in enumerate(job):\n",
    "            machine = task[2]\n",
    "            machine_to_intervals[machine].append(task_vars[(job_id, task_id)][2])\n",
    "\n",
    "    for machine in all_machines:\n",
    "        model.AddNoOverlap(machine_to_intervals[machine])\n",
    "\n",
    "    # H√†m m·ª•c ti√™u: t·ªëi thi·ªÉu makespan\n",
    "    makespan = model.NewIntVar(0, horizon, 'makespan')\n",
    "    for job_id in all_jobs:\n",
    "        last_task_id = len(jobs_data[job_id]) - 1\n",
    "        model.Add(makespan >= task_vars[(job_id, last_task_id)][1])\n",
    "    model.Minimize(makespan)\n",
    "\n",
    "    # Gi·∫£i b√†i to√°n\n",
    "    solver = cp_model.CpSolver()\n",
    "    status = solver.Solve(model)\n",
    "\n",
    "    # Thu th·∫≠p d·ªØ li·ªáu ƒë·ªÉ v·∫Ω\n",
    "    schedule = []\n",
    "    if status == cp_model.OPTIMAL or status == cp_model.FEASIBLE:\n",
    "        print(f'T·ªïng th·ªùi gian ho√†n th√†nh t·ªëi ∆∞u: {solver.Value(makespan)}')\n",
    "        for job_id in all_jobs:\n",
    "            for task_id in range(len(jobs_data[job_id])):\n",
    "                start = solver.Value(task_vars[(job_id, task_id)][0])\n",
    "                duration = jobs_data[job_id][task_id][3]\n",
    "                machine = jobs_data[job_id][task_id][2]\n",
    "                schedule.append((job_id, task_id, machine, start, duration))\n",
    "                print(f'Job {job_id}, Task {task_id}: Machine {machine}, Start {start}, Duration {duration}')\n",
    "    else:\n",
    "        print('Kh√¥ng t√¨m th·∫•y gi·∫£i ph√°p.')\n",
    "        return\n",
    "\n",
    "    # V·∫Ω bi·ªÉu ƒë·ªì Gantt\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    colors = ['#FF9999', '#99CCFF', '#99FF99']  # M√†u cho t·ª´ng Job\n",
    "\n",
    "    for job_id, task_id, machine, start, duration in schedule:\n",
    "        # V·∫Ω h√¨nh ch·ªØ nh·∫≠t cho m·ªói task\n",
    "        ax.add_patch(patches.Rectangle(\n",
    "            (start, machine - 0.4), duration, 0.8, \n",
    "            facecolor=colors[job_id], edgecolor='black',\n",
    "            label=f'Job {job_id}' if task_id == 0 else \"\"\n",
    "        ))\n",
    "        # Ghi ch√∫ tr√™n task\n",
    "        ax.text(start + duration/2, machine, f'J{job_id}-T{task_id}', \n",
    "                ha='center', va='center', color='black')\n",
    "\n",
    "    # Thi·∫øt l·∫≠p bi·ªÉu ƒë·ªì\n",
    "    ax.set_xlim(0, solver.Value(makespan) + 1)\n",
    "    ax.set_ylim(-0.5, machines_count - 0.5)\n",
    "    ax.set_yticks(range(machines_count))\n",
    "    ax.set_yticklabels([f'Machine {m}' for m in all_machines])\n",
    "    ax.set_xlabel('Th·ªùi gian')\n",
    "    ax.set_title('Bi·ªÉu ƒë·ªì Gantt - L·ªãch tr√¨nh Job Shop Scheduling')\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Th√™m ch√∫ th√≠ch (legend) m√† kh√¥ng l·∫∑p l·∫°i\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), loc='upper right')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    solve_and_plot_job_shop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from ortools.sat.python import cp_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def main():\n",
    "    \"\"\"Minimal jobshop problem with Gantt chart visualization.\"\"\"\n",
    "    # Data\n",
    "    jobs_data = [  # task = (machine_id, processing_time)\n",
    "        [(0, 3), (1, 2), (2, 2)],  # Job0\n",
    "        [(0, 2), (2, 1), (1, 4)],  # Job1\n",
    "        [(1, 4), (2, 3)],          # Job2\n",
    "    ]\n",
    "\n",
    "    machines_count = 1 + max(task[0] for job in jobs_data for task in job)\n",
    "    all_machines = range(machines_count)\n",
    "    horizon = sum(task[1] for job in jobs_data for task in job)\n",
    "\n",
    "    # Create the model\n",
    "    model = cp_model.CpModel()\n",
    "\n",
    "    # Named tuple for variables\n",
    "    task_type = collections.namedtuple(\"task_type\", \"start end interval\")\n",
    "    assigned_task_type = collections.namedtuple(\"assigned_task_type\", \"start job index duration\")\n",
    "\n",
    "    # Create job intervals and machine lists\n",
    "    all_tasks = {}\n",
    "    machine_to_intervals = collections.defaultdict(list)\n",
    "\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id, task in enumerate(job):\n",
    "            machine, duration = task\n",
    "            suffix = f\"_{job_id}_{task_id}\"\n",
    "            start_var = model.new_int_var(0, horizon, \"start\" + suffix)\n",
    "            end_var = model.new_int_var(0, horizon, \"end\" + suffix)\n",
    "            interval_var = model.new_interval_var(start_var, duration, end_var, \"interval\" + suffix)\n",
    "            all_tasks[job_id, task_id] = task_type(start=start_var, end=end_var, interval=interval_var)\n",
    "            machine_to_intervals[machine].append(interval_var)\n",
    "\n",
    "    # Add disjunctive constraints (no overlap on machines)\n",
    "    for machine in all_machines:\n",
    "        model.add_no_overlap(machine_to_intervals[machine])\n",
    "\n",
    "    # Add precedence constraints within jobs\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id in range(len(job) - 1):\n",
    "            model.add(all_tasks[job_id, task_id + 1].start >= all_tasks[job_id, task_id].end)\n",
    "\n",
    "    # Makespan objective\n",
    "    obj_var = model.new_int_var(0, horizon, \"makespan\")\n",
    "    model.add_max_equality(obj_var, [all_tasks[job_id, len(job) - 1].end for job_id, job in enumerate(jobs_data)])\n",
    "    model.minimize(obj_var)\n",
    "\n",
    "    # Solve the model\n",
    "    solver = cp_model.CpSolver()\n",
    "    status = solver.solve(model)\n",
    "\n",
    "    if status == cp_model.OPTIMAL or status == cp_model.FEASIBLE:\n",
    "        print(\"Solution:\")\n",
    "        assigned_jobs = collections.defaultdict(list)\n",
    "        schedule = []  # For Gantt chart\n",
    "\n",
    "        # Collect assigned tasks\n",
    "        for job_id, job in enumerate(jobs_data):\n",
    "            for task_id, task in enumerate(job):\n",
    "                machine = task[0]\n",
    "                start = solver.value(all_tasks[job_id, task_id].start)\n",
    "                duration = task[1]\n",
    "                assigned_jobs[machine].append(\n",
    "                    assigned_task_type(start=start, job=job_id, index=task_id, duration=duration)\n",
    "                )\n",
    "                schedule.append((job_id, task_id, machine, start, duration))\n",
    "\n",
    "        # Print solution\n",
    "        output = \"\"\n",
    "        for machine in all_machines:\n",
    "            assigned_jobs[machine].sort()\n",
    "            sol_line_tasks = f\"Machine {machine}: \"\n",
    "            sol_line = \"           \"\n",
    "            for assigned_task in assigned_jobs[machine]:\n",
    "                name = f\"job_{assigned_task.job}_task_{assigned_task.index}\"\n",
    "                sol_line_tasks += f\"{name:15}\"\n",
    "                sol_tmp = f\"[{assigned_task.start},{assigned_task.start + assigned_task.duration}]\"\n",
    "                sol_line += f\"{sol_tmp:15}\"\n",
    "            output += sol_line_tasks + \"\\n\" + sol_line + \"\\n\"\n",
    "        \n",
    "        print(f\"Optimal Schedule Length: {solver.objective_value}\")\n",
    "        print(output)\n",
    "\n",
    "        # Plot Gantt chart\n",
    "        plot_gantt_chart(schedule, machines_count, solver.objective_value)\n",
    "    else:\n",
    "        print(\"No solution found.\")\n",
    "\n",
    "    # Statistics\n",
    "    print(\"\\nStatistics\")\n",
    "    print(f\"  - conflicts: {solver.num_conflicts}\")\n",
    "    print(f\"  - branches : {solver.num_branches}\")\n",
    "    print(f\"  - wall time: {solver.wall_time}s\")\n",
    "\n",
    "def plot_gantt_chart(schedule, machines_count, makespan):\n",
    "    \"\"\"Plot Gantt chart using matplotlib.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    colors = ['#FF9999', '#99CCFF', '#99FF99']  # Colors for Job 0, 1, 2\n",
    "\n",
    "    for job_id, task_id, machine, start, duration in schedule:\n",
    "        ax.add_patch(patches.Rectangle(\n",
    "            (start, machine - 0.4), duration, 0.8,\n",
    "            facecolor=colors[job_id], edgecolor='black',\n",
    "            label=f'Job {job_id}' if task_id == 0 else \"\"\n",
    "        ))\n",
    "        ax.text(start + duration/2, machine, f'J{job_id}-T{task_id}',\n",
    "                ha='center', va='center', color='black')\n",
    "\n",
    "    # Chart settings\n",
    "    ax.set_xlim(0, makespan + 1)\n",
    "    ax.set_ylim(-0.5, machines_count - 0.5)\n",
    "    ax.set_yticks(range(machines_count))\n",
    "    ax.set_yticklabels([f'Machine {m}' for m in range(machines_count)])\n",
    "    ax.set_xlabel('Th·ªùi gian')\n",
    "    ax.set_title('Bi·ªÉu ƒë·ªì Gantt - L·ªãch tr√¨nh Job Shop Scheduling')\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Add legend without duplicates\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), loc='upper right')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from ortools.sat.python import cp_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def main():\n",
    "    \"\"\"Minimal jobshop problem with Gantt chart visualization.\"\"\"\n",
    "    # Data\n",
    "    jobs_data = [  # task = (machine_id, processing_time)\n",
    "        [(0, 3), (1, 2), (2, 2)],  # Job0\n",
    "        [(0, 2), (2, 1), (1, 4)],  # Job1\n",
    "        [(1, 4), (2, 3)],          # Job2\n",
    "    ]\n",
    "\n",
    "    machines_count = 1 + max(task[0] for job in jobs_data for task in job)\n",
    "    all_machines = range(machines_count)\n",
    "    horizon = sum(task[1] for job in jobs_data for task in job)\n",
    "\n",
    "    # Create the model\n",
    "    model = cp_model.CpModel()\n",
    "\n",
    "    # Named tuple for variables\n",
    "    task_type = collections.namedtuple(\"task_type\", \"start end interval\")\n",
    "    assigned_task_type = collections.namedtuple(\"assigned_task_type\", \"start job index duration\")\n",
    "\n",
    "    # Create job intervals and machine lists\n",
    "    all_tasks = {}\n",
    "    machine_to_intervals = collections.defaultdict(list)\n",
    "\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id, task in enumerate(job):\n",
    "            machine, duration = task\n",
    "            suffix = f\"_{job_id}_{task_id}\"\n",
    "            start_var = model.new_int_var(0, horizon, \"start\" + suffix)\n",
    "            end_var = model.new_int_var(0, horizon, \"end\" + suffix)\n",
    "            interval_var = model.new_interval_var(start_var, duration, end_var, \"interval\" + suffix)\n",
    "            all_tasks[job_id, task_id] = task_type(start=start_var, end=end_var, interval=interval_var)\n",
    "            machine_to_intervals[machine].append(interval_var)\n",
    "\n",
    "    # Add disjunctive constraints (no overlap on machines)\n",
    "    for machine in all_machines:\n",
    "        model.add_no_overlap(machine_to_intervals[machine])\n",
    "\n",
    "    # Add precedence constraints within jobs\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id in range(len(job) - 1):\n",
    "            model.add(all_tasks[job_id, task_id + 1].start >= all_tasks[job_id, task_id].end)\n",
    "\n",
    "    # Makespan objective\n",
    "    obj_var = model.new_int_var(0, horizon, \"makespan\")\n",
    "    model.add_max_equality(obj_var, [all_tasks[job_id, len(job) - 1].end for job_id, job in enumerate(jobs_data)])\n",
    "    model.minimize(obj_var)\n",
    "\n",
    "    # Solve the model\n",
    "    solver = cp_model.CpSolver()\n",
    "    status = solver.solve(model)\n",
    "\n",
    "    if status == cp_model.OPTIMAL or status == cp_model.FEASIBLE:\n",
    "        print(\"Solution:\")\n",
    "        assigned_jobs = collections.defaultdict(list)\n",
    "        schedule = []  # For Gantt chart\n",
    "\n",
    "        # Collect assigned tasks\n",
    "        for job_id, job in enumerate(jobs_data):\n",
    "            for task_id, task in enumerate(job):\n",
    "                machine = task[0]\n",
    "                start = solver.value(all_tasks[job_id, task_id].start)\n",
    "                duration = task[1]\n",
    "                assigned_jobs[machine].append(\n",
    "                    assigned_task_type(start=start, job=job_id, index=task_id, duration=duration)\n",
    "                )\n",
    "                schedule.append((job_id, task_id, machine, start, duration))\n",
    "\n",
    "        # Print solution\n",
    "        output = \"\"\n",
    "        for machine in all_machines:\n",
    "            assigned_jobs[machine].sort()\n",
    "            sol_line_tasks = f\"Machine {machine}: \"\n",
    "            sol_line = \"           \"\n",
    "            for assigned_task in assigned_jobs[machine]:\n",
    "                name = f\"job_{assigned_task.job}_task_{assigned_task.index}\"\n",
    "                sol_line_tasks += f\"{name:15}\"\n",
    "                sol_tmp = f\"[{assigned_task.start},{assigned_task.start + assigned_task.duration}]\"\n",
    "                sol_line += f\"{sol_tmp:15}\"\n",
    "            output += sol_line_tasks + \"\\n\" + sol_line + \"\\n\"\n",
    "        \n",
    "        print(f\"Optimal Schedule Length: {solver.objective_value}\")\n",
    "        print(output)\n",
    "\n",
    "        # Plot Gantt chart with clear time labels\n",
    "        plot_gantt_chart(schedule, machines_count, solver.objective_value)\n",
    "    else:\n",
    "        print(\"No solution found.\")\n",
    "\n",
    "    # Statistics\n",
    "    print(\"\\nStatistics\")\n",
    "    print(f\"  - conflicts: {solver.num_conflicts}\")\n",
    "    print(f\"  - branches : {solver.num_branches}\")\n",
    "    print(f\"  - wall time: {solver.wall_time}s\")\n",
    "\n",
    "def plot_gantt_chart(schedule, machines_count, makespan):\n",
    "    \"\"\"Plot Gantt chart with clear time labels using matplotlib.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))  # TƒÉng k√≠ch th∆∞·ªõc ƒë·ªÉ r√µ h∆°n\n",
    "    colors = ['#FF9999', '#99CCFF', '#99FF99']  # Colors for Job 0, 1, 2\n",
    "\n",
    "    for job_id, task_id, machine, start, duration in schedule:\n",
    "        ax.add_patch(patches.Rectangle(\n",
    "            (start, machine - 0.4), duration, 0.8,\n",
    "            facecolor=colors[job_id], edgecolor='black',\n",
    "            label=f'Job {job_id}' if task_id == 0 else \"\"\n",
    "        ))\n",
    "        ax.text(start + duration/2, machine, f'J{job_id}-T{task_id}',\n",
    "                ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "    # Chart settings with clear time ticks\n",
    "    ax.set_xlim(0, makespan + 1)\n",
    "    ax.set_ylim(-0.5, machines_count - 0.5)\n",
    "    ax.set_yticks(range(machines_count))\n",
    "    ax.set_yticklabels([f'Machine {m}' for m in range(machines_count)])\n",
    "\n",
    "    # Th√™m m·ªëc th·ªùi gian chi ti·∫øt tr√™n tr·ª•c x\n",
    "    time_ticks = range(0, int(makespan) + 1, 1)  # M·ªói ƒë∆°n v·ªã th·ªùi gian l√† 1\n",
    "    ax.set_xticks(time_ticks)\n",
    "    ax.set_xticklabels([str(t) for t in time_ticks], rotation=45, ha='right')  # Xoay nh√£n cho d·ªÖ ƒë·ªçc\n",
    "    ax.set_xlabel('Th·ªùi gian')\n",
    "    ax.set_title('Bi·ªÉu ƒë·ªì Gantt - L·ªãch tr√¨nh Job Shop Scheduling')\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Add legend without duplicates\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), loc='upper right')\n",
    "\n",
    "    plt.tight_layout()  # T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh kho·∫£ng c√°ch ƒë·ªÉ tr√°nh ch·ªìng l·∫•n\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from ortools.sat.python import cp_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def main():\n",
    "    \"\"\"Minimal jobshop problem with Gantt chart visualization.\"\"\"\n",
    "    # Data\n",
    "    jobs_data = [  # task = (machine_id, processing_time)\n",
    "        [(0, 3), (1, 2), (2, 2)],  # Job0\n",
    "        [(0, 2), (2, 1), (1, 4)],  # Job1\n",
    "        [(1, 4), (2, 3)],          # Job2\n",
    "    ]\n",
    "\n",
    "    machines_count = 1 + max(task[0] for job in jobs_data for task in job)\n",
    "    all_machines = range(machines_count)\n",
    "    horizon = sum(task[1] for job in jobs_data for task in job)\n",
    "\n",
    "    # Create the model\n",
    "    model = cp_model.CpModel()\n",
    "\n",
    "    # Named tuple for variables\n",
    "    task_type = collections.namedtuple(\"task_type\", \"start end interval\")\n",
    "    assigned_task_type = collections.namedtuple(\"assigned_task_type\", \"start job index duration\")\n",
    "\n",
    "    # Create job intervals and machine lists\n",
    "    all_tasks = {}\n",
    "    machine_to_intervals = collections.defaultdict(list)\n",
    "\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id, task in enumerate(job):\n",
    "            machine, duration = task\n",
    "            suffix = f\"_{job_id}_{task_id}\"\n",
    "            start_var = model.new_int_var(0, horizon, \"start\" + suffix)\n",
    "            end_var = model.new_int_var(0, horizon, \"end\" + suffix)\n",
    "            interval_var = model.new_interval_var(start_var, duration, end_var, \"interval\" + suffix)\n",
    "            all_tasks[job_id, task_id] = task_type(start=start_var, end=end_var, interval=interval_var)\n",
    "            machine_to_intervals[machine].append(interval_var)\n",
    "\n",
    "    # Add disjunctive constraints (no overlap on machines)\n",
    "    for machine in all_machines:\n",
    "        model.add_no_overlap(machine_to_intervals[machine])\n",
    "\n",
    "    # Add precedence constraints within jobs\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id in range(len(job) - 1):\n",
    "            model.add(all_tasks[job_id, task_id + 1].start >= all_tasks[job_id, task_id].end)\n",
    "\n",
    "    # Makespan objective\n",
    "    obj_var = model.new_int_var(0, horizon, \"makespan\")\n",
    "    model.add_max_equality(obj_var, [all_tasks[job_id, len(job) - 1].end for job_id, job in enumerate(jobs_data)])\n",
    "    model.minimize(obj_var)\n",
    "\n",
    "    # Solve the model\n",
    "    solver = cp_model.CpSolver()\n",
    "    status = solver.solve(model)\n",
    "\n",
    "    if status == cp_model.OPTIMAL or status == cp_model.FEASIBLE:\n",
    "        print(\"Solution:\")\n",
    "        assigned_jobs = collections.defaultdict(list)\n",
    "        schedule = []  # For Gantt chart\n",
    "\n",
    "        # Collect assigned tasks\n",
    "        for job_id, job in enumerate(jobs_data):\n",
    "            for task_id, task in enumerate(job):\n",
    "                machine = task[0]\n",
    "                start = solver.value(all_tasks[job_id, task_id].start)\n",
    "                duration = task[1]\n",
    "                assigned_jobs[machine].append(\n",
    "                    assigned_task_type(start=start, job=job_id, index=task_id, duration=duration)\n",
    "                )\n",
    "                schedule.append((job_id, task_id, machine, start, duration))\n",
    "\n",
    "        # Print solution\n",
    "        output = \"\"\n",
    "        for machine in all_machines:\n",
    "            assigned_jobs[machine].sort()\n",
    "            sol_line_tasks = f\"Machine {machine}: \"\n",
    "            sol_line = \"           \"\n",
    "            for assigned_task in assigned_jobs[machine]:\n",
    "                name = f\"job_{assigned_task.job}_task_{assigned_task.index}\"\n",
    "                sol_line_tasks += f\"{name:15}\"\n",
    "                sol_tmp = f\"[{assigned_task.start},{assigned_task.start + assigned_task.duration}]\"\n",
    "                sol_line += f\"{sol_tmp:15}\"\n",
    "            output += sol_line_tasks + \"\\n\" + sol_line + \"\\n\"\n",
    "        \n",
    "        print(f\"Optimal Schedule Length: {solver.objective_value}\")\n",
    "        print(output)\n",
    "\n",
    "        # Plot Gantt chart with clear time labels\n",
    "        plot_gantt_chart(schedule, machines_count, solver.objective_value)\n",
    "    else:\n",
    "        print(\"No solution found.\")\n",
    "\n",
    "    # Statistics\n",
    "    print(\"\\nStatistics\")\n",
    "    print(f\"  - conflicts: {solver.num_conflicts}\")\n",
    "    print(f\"  - branches : {solver.num_branches}\")\n",
    "    print(f\"  - wall time: {solver.wall_time}s\")\n",
    "\n",
    "def plot_gantt_chart(schedule, machines_count, makespan):\n",
    "    \"\"\"Plot Gantt chart with straight time labels using matplotlib.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))  # K√≠ch th∆∞·ªõc bi·ªÉu ƒë·ªì\n",
    "    colors = ['#FF9999', '#99CCFF', '#99FF99']  # Colors for Job 0, 1, 2\n",
    "\n",
    "    for job_id, task_id, machine, start, duration in schedule:\n",
    "        ax.add_patch(patches.Rectangle(\n",
    "            (start, machine - 0.4), duration, 0.8,\n",
    "            facecolor=colors[job_id], edgecolor='black',\n",
    "            label=f'Job {job_id}' if task_id == 0 else \"\"\n",
    "        ))\n",
    "        ax.text(start + duration/2, machine, f'J{job_id}-T{task_id}',\n",
    "                ha='center', va='center', color='black', fontsize=10)\n",
    "\n",
    "    # Chart settings with clear and straight time ticks\n",
    "    ax.set_xlim(0, makespan + 1)\n",
    "    ax.set_ylim(-0.5, machines_count - 0.5)\n",
    "    ax.set_yticks(range(machines_count))\n",
    "    ax.set_yticklabels([f'Machine {m}' for m in range(machines_count)])\n",
    "\n",
    "    # Th√™m m·ªëc th·ªùi gian chi ti·∫øt tr√™n tr·ª•c x, gi·ªØ th·∫≥ng\n",
    "    time_ticks = range(0, int(makespan) + 1, 1)  # M·ªói ƒë∆°n v·ªã th·ªùi gian l√† 1\n",
    "    ax.set_xticks(time_ticks)\n",
    "    ax.set_xticklabels([str(t) for t in time_ticks], ha='center')  # Gi·ªØ th·∫≥ng, cƒÉn gi·ªØa\n",
    "    ax.set_xlabel('Th·ªùi gian')\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), loc='upper right')\n",
    "\n",
    "    plt.tight_layout()  \n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from ortools.sat.python import cp_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def main():\n",
    "    \"\"\"Job Shop Scheduling with Gantt chart visualization.\"\"\"\n",
    "    # Data: task = (machine_id, processing_time)\n",
    "    jobs_data = [\n",
    "        [(0, 3), (1, 2), (2, 2)],  # J0: O1(0,3), O2(1,2), O3(2,2)\n",
    "        [(0, 2), (2, 1), (1, 4)],  # J1: O1(0,2), O2(2,1), O3(1,4)\n",
    "        [(1, 4), (2, 3)],          # J2: O1(1,4), O2(2,3), (b·ªè qua O3)\n",
    "    ]\n",
    "\n",
    "    machines_count = 1 + max(task[0] for job in jobs_data for task in job)\n",
    "    all_machines = range(machines_count)\n",
    "    horizon = sum(task[1] for job in jobs_data for task in job)\n",
    "\n",
    "    # Create the model\n",
    "    model = cp_model.CpModel()\n",
    "\n",
    "    # Named tuple for variables\n",
    "    task_type = collections.namedtuple(\"task_type\", \"start end interval\")\n",
    "    assigned_task_type = collections.namedtuple(\"assigned_task_type\", \"start job index duration\")\n",
    "\n",
    "    # Create job intervals and machine lists\n",
    "    all_tasks = {}\n",
    "    machine_to_intervals = collections.defaultdict(list)\n",
    "\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id, task in enumerate(job):\n",
    "            machine, duration = task\n",
    "            if duration == 0:  # B·ªè qua task c√≥ duration = 0 (nh∆∞ O3 c·ªßa J2)\n",
    "                continue\n",
    "            suffix = f\"_{job_id}_{task_id}\"\n",
    "            start_var = model.new_int_var(0, horizon, \"start\" + suffix)\n",
    "            end_var = model.new_int_var(0, horizon, \"end\" + suffix)\n",
    "            interval_var = model.new_interval_var(start_var, duration, end_var, \"interval\" + suffix)\n",
    "            all_tasks[job_id, task_id] = task_type(start=start_var, end=end_var, interval=interval_var)\n",
    "            machine_to_intervals[machine].append(interval_var)\n",
    "\n",
    "    # Add disjunctive constraints (no overlap on machines)\n",
    "    for machine in all_machines:\n",
    "        model.add_no_overlap(machine_to_intervals[machine])\n",
    "\n",
    "    # Add precedence constraints within jobs\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id in range(len(job) - 1):\n",
    "            if (job_id, task_id) in all_tasks and (job_id, task_id + 1) in all_tasks:  # Ch·ªâ th√™m n·∫øu task t·ªìn t·∫°i\n",
    "                model.add(all_tasks[job_id, task_id + 1].start >= all_tasks[job_id, task_id].end)\n",
    "\n",
    "    # Makespan objective\n",
    "    obj_var = model.new_int_var(0, horizon, \"makespan\")\n",
    "    model.add_max_equality(obj_var, [all_tasks[job_id, len(job) - 1].end \n",
    "                                    for job_id, job in enumerate(jobs_data) \n",
    "                                    if (job_id, len(job) - 1) in all_tasks])\n",
    "    model.minimize(obj_var)\n",
    "\n",
    "    # Solve the model\n",
    "    solver = cp_model.CpSolver()\n",
    "    status = solver.solve(model)\n",
    "\n",
    "    if status == cp_model.OPTIMAL or status == cp_model.FEASIBLE:\n",
    "        print(\"Solution:\")\n",
    "        assigned_jobs = collections.defaultdict(list)\n",
    "        schedule = []  # For Gantt chart\n",
    "\n",
    "        # Collect assigned tasks\n",
    "        for job_id, job in enumerate(jobs_data):\n",
    "            for task_id, task in enumerate(job):\n",
    "                machine, duration = task\n",
    "                if duration == 0:\n",
    "                    continue\n",
    "                start = solver.value(all_tasks[job_id, task_id].start)\n",
    "                assigned_jobs[machine].append(\n",
    "                    assigned_task_type(start=start, job=job_id, index=task_id, duration=duration)\n",
    "                )\n",
    "                schedule.append((job_id, task_id, machine, start, duration))\n",
    "\n",
    "        # Print solution\n",
    "        output = \"\"\n",
    "        for machine in all_machines:\n",
    "            assigned_jobs[machine].sort()\n",
    "            sol_line_tasks = f\"Machine {machine}: \"\n",
    "            sol_line = \"           \"\n",
    "            for assigned_task in assigned_jobs[machine]:\n",
    "                name = f\"J{assigned_task.job}-O{assigned_task.index + 1}\"\n",
    "                sol_line_tasks += f\"{name:15}\"\n",
    "                sol_tmp = f\"[{assigned_task.start},{assigned_task.start + assigned_task.duration}]\"\n",
    "                sol_line += f\"{sol_tmp:15}\"\n",
    "            output += sol_line_tasks + \"\\n\" + sol_line + \"\\n\"\n",
    "        \n",
    "        print(f\"Optimal Schedule Length: {solver.objective_value}\")\n",
    "        print(output)\n",
    "\n",
    "        # Plot Gantt chart\n",
    "        plot_gantt_chart(schedule, machines_count, solver.objective_value)\n",
    "    else:\n",
    "        print(\"No solution found.\")\n",
    "\n",
    "def plot_gantt_chart(schedule, machines_count, makespan):\n",
    "    \"\"\"Plot Gantt chart with J and O labels.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    colors = ['#FF9999', '#99CCFF', '#99FF99']  # Colors for J0, J1, J2\n",
    "\n",
    "    for job_id, task_id, machine, start, duration in schedule:\n",
    "        ax.add_patch(patches.Rectangle(\n",
    "            (start, machine - 0.4), duration, 0.8,\n",
    "            facecolor=colors[job_id], edgecolor='black',\n",
    "            label=f'J{job_id}' if task_id == 0 else \"\"\n",
    "        ))\n",
    "        # Hi·ªÉn th·ªã J v√† O tr√™n task\n",
    "        ax.text(start + duration/2, machine, f'J{job_id}-O{task_id + 1}',\n",
    "                ha='center', va='center', color='black', fontsize=20)\n",
    "\n",
    "    # Chart settings with clear time ticks\n",
    "    ax.set_xlim(0, makespan + 1)\n",
    "    ax.set_ylim(-0.5, machines_count - 0.5)\n",
    "    \n",
    "    ax.set_yticks(range(machines_count))\n",
    "    ax.set_yticklabels([f'Machine {m}' for m in range(machines_count)], fontsize=20, fontweight='bold')\n",
    "\n",
    "\n",
    "    # Th√™m m·ªëc th·ªùi gian chi ti·∫øt tr√™n tr·ª•c x\n",
    "    time_ticks = range(0, int(makespan) + 1, 1)\n",
    "    ax.set_xticks(time_ticks)\n",
    "    ax.set_xticklabels([str(t) for t in time_ticks], ha='center')\n",
    "    ax.set_xlabel('Th·ªùi gian', fontsize=20, fontweight='bold')\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Add legend without duplicates\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from ortools.sat.python import cp_model\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Minimal jobshop problem with Gantt chart.\"\"\"\n",
    "    # Data.\n",
    "    jobs_data = [  # task = (machine_id, processing_time).\n",
    "        [(0, 3), (1, 2), (2, 2)],  # Job0\n",
    "        [(0, 2), (2, 1), (1, 4)],  # Job1\n",
    "        [(1, 4), (2, 3)],  # Job2\n",
    "    ]\n",
    "\n",
    "    machines_count = 1 + max(task[0] for job in jobs_data for task in job)\n",
    "    all_machines = range(machines_count)\n",
    "    horizon = sum(task[1] for job in jobs_data for task in job)\n",
    "\n",
    "    # Create the model.\n",
    "    model = cp_model.CpModel()\n",
    "    task_type = collections.namedtuple(\"task_type\", \"start end interval\")\n",
    "    assigned_task_type = collections.namedtuple(\n",
    "        \"assigned_task_type\", \"start job index duration\"\n",
    "    )\n",
    "\n",
    "    all_tasks = {}\n",
    "    machine_to_intervals = collections.defaultdict(list)\n",
    "\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id, task in enumerate(job):\n",
    "            machine, duration = task\n",
    "            suffix = f\"_{job_id}_{task_id}\"\n",
    "            start_var = model.new_int_var(0, horizon, \"start\" + suffix)\n",
    "            end_var = model.new_int_var(0, horizon, \"end\" + suffix)\n",
    "            interval_var = model.new_interval_var(\n",
    "                start_var, duration, end_var, \"interval\" + suffix\n",
    "            )\n",
    "            all_tasks[job_id, task_id] = task_type(\n",
    "                start=start_var, end=end_var, interval=interval_var\n",
    "            )\n",
    "            machine_to_intervals[machine].append(interval_var)\n",
    "\n",
    "    for machine in all_machines:\n",
    "        model.add_no_overlap(machine_to_intervals[machine])\n",
    "\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id in range(len(job) - 1):\n",
    "            model.add(\n",
    "                all_tasks[job_id, task_id + 1].start >= all_tasks[job_id, task_id].end\n",
    "            )\n",
    "\n",
    "    obj_var = model.new_int_var(0, horizon, \"makespan\")\n",
    "    model.add_max_equality(\n",
    "        obj_var,\n",
    "        [all_tasks[job_id, len(job) - 1].end for job_id, job in enumerate(jobs_data)],\n",
    "    )\n",
    "    model.minimize(obj_var)\n",
    "\n",
    "    solver = cp_model.CpSolver()\n",
    "    status = solver.solve(model)\n",
    "\n",
    "    if status == cp_model.OPTIMAL or status == cp_model.FEASIBLE:\n",
    "        print(\"Solution:\")\n",
    "        assigned_jobs = collections.defaultdict(list)\n",
    "        for job_id, job in enumerate(jobs_data):\n",
    "            for task_id, task in enumerate(job):\n",
    "                machine = task[0]\n",
    "                assigned_jobs[machine].append(\n",
    "                    assigned_task_type(\n",
    "                        start=solver.value(all_tasks[job_id, task_id].start),\n",
    "                        job=job_id,\n",
    "                        index=task_id,\n",
    "                        duration=task[1],\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        output = \"\"\n",
    "        for machine in all_machines:\n",
    "            assigned_jobs[machine].sort()\n",
    "            sol_line_tasks = \"Machine \" + str(machine) + \": \"\n",
    "            sol_line = \"           \"\n",
    "            for assigned_task in assigned_jobs[machine]:\n",
    "                name = f\"job_{assigned_task.job}_task_{assigned_task.index}\"\n",
    "                sol_line_tasks += f\"{name:15}\"\n",
    "                start = assigned_task.start\n",
    "                duration = assigned_task.duration\n",
    "                sol_tmp = f\"[{start},{start + duration}]\"\n",
    "                sol_line += f\"{sol_tmp:15}\"\n",
    "            sol_line += \"\\n\"\n",
    "            sol_line_tasks += \"\\n\"\n",
    "            output += sol_line_tasks\n",
    "            output += sol_line\n",
    "\n",
    "        print(f\"Optimal Schedule Length: {solver.objective_value}\")\n",
    "        print(output)\n",
    "\n",
    "        # V·∫Ω bi·ªÉu ƒë·ªì Gantt\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        colors = [\"red\", \"blue\", \"green\", \"orange\", \"purple\"]\n",
    "        for machine in all_machines:\n",
    "            for assigned_task in assigned_jobs[machine]:\n",
    "                start = assigned_task.start\n",
    "                duration = assigned_task.duration\n",
    "                job_id = assigned_task.job\n",
    "                task_label = f\"J{job_id}-T{assigned_task.index}\"\n",
    "                ax.broken_barh([(start, duration)], (machine - 0.4, 0.8),\n",
    "                               facecolors=colors[job_id % len(colors)], label=task_label)\n",
    "\n",
    "        ax.set_xlabel(\"Time\")\n",
    "        ax.set_ylabel(\"Machines\")\n",
    "        ax.set_yticks(list(all_machines))\n",
    "        ax.set_yticklabels([f\"Machine {m}\" for m in all_machines])\n",
    "        ax.grid(True)\n",
    "\n",
    "        plt.title(\"Gantt Chart for Job Shop Scheduling\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No solution found.\")\n",
    "\n",
    "    print(\"\\nStatistics\")\n",
    "    print(f\"  - conflicts: {solver.num_conflicts}\")\n",
    "    print(f\"  - branches : {solver.num_branches}\")\n",
    "    print(f\"  - wall time: {solver.wall_time}s\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Minimal jobshop example.\"\"\"\n",
    "import collections\n",
    "from ortools.sat.python import cp_model\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Minimal jobshop problem.\"\"\"\n",
    "    # Data.\n",
    "    jobs_data = [  # task = (machine_id, processing_time).\n",
    "        [(0, 3), (1, 2), (2, 2)],  # Job0\n",
    "        [(0, 2), (2, 1), (1, 4)],  # Job1\n",
    "        [(1, 4), (2, 3)],  # Job2\n",
    "    ]\n",
    "\n",
    "    machines_count = 1 + max(task[0] for job in jobs_data for task in job)\n",
    "    all_machines = range(machines_count)\n",
    "    # Computes horizon dynamically as the sum of all durations.\n",
    "    horizon = sum(task[1] for job in jobs_data for task in job)\n",
    "\n",
    "    # Create the model.\n",
    "    model = cp_model.CpModel()\n",
    "\n",
    "    # Named tuple to store information about created variables.\n",
    "    task_type = collections.namedtuple(\"task_type\", \"start end interval\")\n",
    "    # Named tuple to manipulate solution information.\n",
    "    assigned_task_type = collections.namedtuple(\n",
    "        \"assigned_task_type\", \"start job index duration\"\n",
    "    )\n",
    "\n",
    "    # Creates job intervals and add to the corresponding machine lists.\n",
    "    all_tasks = {}\n",
    "    machine_to_intervals = collections.defaultdict(list)\n",
    "\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id, task in enumerate(job):\n",
    "            machine, duration = task\n",
    "            suffix = f\"_{job_id}_{task_id}\"\n",
    "            start_var = model.new_int_var(0, horizon, \"start\" + suffix)\n",
    "            end_var = model.new_int_var(0, horizon, \"end\" + suffix)\n",
    "            interval_var = model.new_interval_var(\n",
    "                start_var, duration, end_var, \"interval\" + suffix\n",
    "            )\n",
    "            all_tasks[job_id, task_id] = task_type(\n",
    "                start=start_var, end=end_var, interval=interval_var\n",
    "            )\n",
    "            machine_to_intervals[machine].append(interval_var)\n",
    "\n",
    "    # Create and add disjunctive constraints.\n",
    "    for machine in all_machines:\n",
    "        model.add_no_overlap(machine_to_intervals[machine])\n",
    "\n",
    "    # Precedences inside a job.\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id in range(len(job) - 1):\n",
    "            model.add(\n",
    "                all_tasks[job_id, task_id + 1].start >= all_tasks[job_id, task_id].end\n",
    "            )\n",
    "\n",
    "    # Makespan objective.\n",
    "    obj_var = model.new_int_var(0, horizon, \"makespan\")\n",
    "    model.add_max_equality(\n",
    "        obj_var,\n",
    "        [all_tasks[job_id, len(job) - 1].end for job_id, job in enumerate(jobs_data)],\n",
    "    )\n",
    "    model.minimize(obj_var)\n",
    "\n",
    "    # Creates the solver and solve.\n",
    "    solver = cp_model.CpSolver()\n",
    "    status = solver.solve(model)\n",
    "\n",
    "    if status == cp_model.OPTIMAL or status == cp_model.FEASIBLE:\n",
    "        print(\"Solution:\")\n",
    "        # Create one list of assigned tasks per machine.\n",
    "        assigned_jobs = collections.defaultdict(list)\n",
    "        for job_id, job in enumerate(jobs_data):\n",
    "            for task_id, task in enumerate(job):\n",
    "                machine = task[0]\n",
    "                assigned_jobs[machine].append(\n",
    "                    assigned_task_type(\n",
    "                        start=solver.value(all_tasks[job_id, task_id].start),\n",
    "                        job=job_id,\n",
    "                        index=task_id,\n",
    "                        duration=task[1],\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        # Create per machine output lines.\n",
    "        output = \"\"\n",
    "        for machine in all_machines:\n",
    "            # Sort by starting time.\n",
    "            assigned_jobs[machine].sort()\n",
    "            sol_line_tasks = \"Machine \" + str(machine) + \": \"\n",
    "            sol_line = \"           \"\n",
    "\n",
    "            for assigned_task in assigned_jobs[machine]:\n",
    "                name = f\"job_{assigned_task.job}_task_{assigned_task.index}\"\n",
    "                # add spaces to output to align columns.\n",
    "                sol_line_tasks += f\"{name:15}\"\n",
    "\n",
    "                start = assigned_task.start\n",
    "                duration = assigned_task.duration\n",
    "                sol_tmp = f\"[{start},{start + duration}]\"\n",
    "                # add spaces to output to align columns.\n",
    "                sol_line += f\"{sol_tmp:15}\"\n",
    "\n",
    "            sol_line += \"\\n\"\n",
    "            sol_line_tasks += \"\\n\"\n",
    "            output += sol_line_tasks\n",
    "            output += sol_line\n",
    "\n",
    "        # Finally print the solution found.\n",
    "        print(f\"Optimal Schedule Length: {solver.objective_value}\")\n",
    "        print(output)\n",
    "    else:\n",
    "        print(\"No solution found.\")\n",
    "\n",
    "    # Statistics.\n",
    "    print(\"\\nStatistics\")\n",
    "    print(f\"  - conflicts: {solver.num_conflicts}\")\n",
    "    print(f\"  - branches : {solver.num_branches}\")\n",
    "    print(f\"  - wall time: {solver.wall_time}s\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Danh s√°ch m√°y v√† c√¥ng vi·ªác\n",
    "machines = [\"Machine 0\", \"Machine 1\", \"Machine 2\"]\n",
    "tasks = [\n",
    "    (0, 0, 2, \"J0-O1\"), (2, 2, 3, \"J0-O2\"), (5, 0, 2, \"J0-O3\"),\n",
    "    (0, 0, 2, \"J1-O1\"), (2, 2, 1, \"J1-O2\"), (3, 1, 2, \"J1-O3\"),\n",
    "    (0, 2, 2, \"J2-O1\"), (2, 0, 3, \"J2-O2\"), (5, 1, 1, \"J2-O3\")\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "for start, machine, duration, label in tasks:\n",
    "    ax.add_patch(mpatches.Rectangle((start, machine), duration, 0.8, facecolor=\"lightblue\", edgecolor=\"black\"))\n",
    "    ax.text(start + duration / 2, machine + 0.4, label, ha='center', va='center', fontsize=10, color='black')\n",
    "\n",
    "ax.set_yticks(range(len(machines)))\n",
    "ax.set_yticklabels(machines)\n",
    "ax.set_xlabel(\"Th·ªùi gian\")\n",
    "ax.set_title(\"Bi·ªÉu ƒë·ªì Gantt cho FJSS\")\n",
    "\n",
    "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.sat.python import cp_model\n",
    "\n",
    "def solve_fjss():\n",
    "    \n",
    "    jobs_data = [\n",
    "        [[(0, 2), (1, 3)], [(1, 1), (2, 4)], [(0, 3), (2, 2)]],\n",
    "        [[(1, 3), (2, 2)], [(0, 4), (1, 2)], [(1, 2), (2, 3)]],\n",
    "        [[(0, 4), (2, 1)], [(1, 3), (2, 2)], [(0, 2), (1, 4)]],\n",
    "    ]\n",
    "\n",
    "    num_jobs = len(jobs_data)\n",
    "    num_machines = 3\n",
    "    all_machines = range(num_machines)\n",
    "\n",
    "    # Kh·ªüi t·∫°o m√¥ h√¨nh\n",
    "    model = cp_model.CpModel()\n",
    "\n",
    "    # T√≠nh th·ªùi gian t·ªëi ƒëa c√≥ th·ªÉ x·∫£y ra (ƒë·ªÉ l√†m gi·ªõi h·∫°n tr√™n cho bi·∫øn)\n",
    "    horizon = sum(task[1] for job in jobs_data for operation in job for task in operation)\n",
    "    \n",
    "    # T·∫°o bi·∫øn: (job_id, operation_id, machine_id) -> (start, duration, end)\n",
    "    task_to_interval = {}\n",
    "    task_to_machine = {}\n",
    "    for job_id in range(num_jobs):\n",
    "        for op_id in range(len(jobs_data[job_id])):\n",
    "            for task_id, (machine_id, duration) in enumerate(jobs_data[job_id][op_id]):\n",
    "                suffix = f'_j{job_id}_o{op_id}_m{machine_id}'\n",
    "                start_var = model.NewIntVar(0, horizon, 'start' + suffix)\n",
    "                end_var = model.NewIntVar(0, horizon, 'end' + suffix)\n",
    "                interval_var = model.NewIntervalVar(start_var, duration, end_var, 'interval' + suffix)\n",
    "                task_to_interval[(job_id, op_id, machine_id)] = interval_var\n",
    "                task_to_machine[(job_id, op_id, machine_id)] = machine_id\n",
    "\n",
    "    # T·∫°o bi·∫øn ƒë·ªÉ ch·ªçn m√°y cho m·ªói thao t√°c\n",
    "    machine_selection = {}\n",
    "    for job_id in range(num_jobs):\n",
    "        for op_id in range(len(jobs_data[job_id])):\n",
    "            tasks = jobs_data[job_id][op_id]\n",
    "            task_literals = []\n",
    "            for task_id, (machine_id, _) in enumerate(tasks):\n",
    "                literal = model.NewBoolVar(f'j{job_id}_o{op_id}_m{machine_id}')\n",
    "                task_literals.append(literal)\n",
    "                machine_selection[(job_id, op_id, machine_id)] = literal\n",
    "            # Ch·ªâ m·ªôt m√°y ƒë∆∞·ª£c ch·ªçn cho m·ªói thao t√°c\n",
    "            model.AddExactlyOne(task_literals)\n",
    "\n",
    "    # R√†ng bu·ªôc: C√°c thao t√°c trong c√πng m·ªôt c√¥ng vi·ªác ph·∫£i th·ª±c hi·ªán theo th·ª© t·ª±\n",
    "    for job_id in range(num_jobs):\n",
    "        for op_id in range(len(jobs_data[job_id]) - 1):\n",
    "            possible_machines_curr = jobs_data[job_id][op_id]\n",
    "            possible_machines_next = jobs_data[job_id][op_id + 1]\n",
    "            for _, (machine_curr, _) in enumerate(possible_machines_curr):\n",
    "                for _, (machine_next, _) in enumerate(possible_machines_next):\n",
    "                    curr_end = task_to_interval[(job_id, op_id, machine_curr)].EndExpr()\n",
    "                    next_start = task_to_interval[(job_id, op_id + 1, machine_next)].StartExpr()\n",
    "                    model.Add(curr_end <= next_start).OnlyEnforceIf([\n",
    "                        machine_selection[(job_id, op_id, machine_curr)],\n",
    "                        machine_selection[(job_id, op_id + 1, machine_next)]\n",
    "                    ])\n",
    "\n",
    "    # R√†ng bu·ªôc: Kh√¥ng c√≥ hai thao t√°c n√†o tr√™n c√πng m·ªôt m√°y ƒë∆∞·ª£c ch·ªìng l·∫•p\n",
    "    for machine_id in all_machines:\n",
    "        intervals = []\n",
    "        for job_id in range(num_jobs):\n",
    "            for op_id in range(len(jobs_data[job_id])):\n",
    "                for task_id, (m_id, _) in enumerate(jobs_data[job_id][op_id]):\n",
    "                    if m_id == machine_id:\n",
    "                        interval = task_to_interval[(job_id, op_id, m_id)]\n",
    "                        intervals.append(interval)\n",
    "                        model.Add(interval.StartExpr() >= 0).OnlyEnforceIf(machine_selection[(job_id, op_id, m_id)])\n",
    "        model.AddNoOverlap(intervals)\n",
    "\n",
    "    # M·ª•c ti√™u: T·ªëi thi·ªÉu h√≥a th·ªùi gian ho√†n th√†nh t·ªëi ƒëa (C_max)\n",
    "    c_max = model.NewIntVar(0, horizon, 'c_max')\n",
    "    for job_id in range(num_jobs):\n",
    "        last_op_id = len(jobs_data[job_id]) - 1\n",
    "        possible_machines = jobs_data[job_id][last_op_id]\n",
    "        for _, (machine_id, _) in enumerate(possible_machines):\n",
    "            end_time = task_to_interval[(job_id, last_op_id, machine_id)].EndExpr()\n",
    "            model.Add(c_max >= end_time).OnlyEnforceIf(machine_selection[(job_id, last_op_id, machine_id)])\n",
    "    model.Minimize(c_max)\n",
    "\n",
    "    # Gi·∫£i b√†i to√°n\n",
    "    solver = cp_model.CpSolver()\n",
    "    status = solver.Solve(model)\n",
    "\n",
    "    # In k·∫øt qu·∫£\n",
    "    if status == cp_model.OPTIMAL or status == cp_model.FEASIBLE:\n",
    "        print(f'T·ªïng th·ªùi gian ho√†n th√†nh t·ªëi ƒëa (C_max): {solver.ObjectiveValue()}')\n",
    "        print('\\nL·ªãch tr√¨nh:')\n",
    "        for job_id in range(num_jobs):\n",
    "            print(f'C√¥ng vi·ªác {job_id}:')\n",
    "            for op_id in range(len(jobs_data[job_id])):\n",
    "                for task_id, (machine_id, duration) in enumerate(jobs_data[job_id][op_id]):\n",
    "                    if solver.Value(machine_selection[(job_id, op_id, machine_id)]) == 1:\n",
    "                        start = solver.Value(task_to_interval[(job_id, op_id, machine_id)].StartExpr())\n",
    "                        end = solver.Value(task_to_interval[(job_id, op_id, machine_id)].EndExpr())\n",
    "                        print(f'  Thao t√°c {op_id} tr√™n m√°y {machine_id}: b·∫Øt ƒë·∫ßu {start}, k·∫øt th√∫c {end}, th·ªùi gian x·ª≠ l√Ω {duration}')\n",
    "    else:\n",
    "        print('Kh√¥ng t√¨m th·∫•y l·ªãch tr√¨nh kh·∫£ thi.')\n",
    "\n",
    "# Ch·∫°y ch∆∞∆°ng tr√¨nh\n",
    "solve_fjss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.sat.python import cp_model\n",
    "\n",
    "def solve_fjss():\n",
    "    # D·ªØ li·ªáu ƒë·∫ßu v√†o\n",
    "    jobs_data = [\n",
    "        # Job 0\n",
    "        [[(0, 3), (1, 2)], [(1, 2), (2, 3)], [(0, 2), (2, 2)]],\n",
    "        # Job 1\n",
    "        [[(0, 2), (2, 4)], [(1, 3), (2, 1)], [(0, 4), (1, 2)]],\n",
    "        # Job 2\n",
    "        [[(1, 4), (2, 2)], [(0, 3), (2, 3)], [(1, 1), (2, 3)]],\n",
    "    ]\n",
    "\n",
    "    num_jobs = len(jobs_data)\n",
    "    num_machines = 3\n",
    "    all_machines = range(num_machines)\n",
    "\n",
    "    # Kh·ªüi t·∫°o m√¥ h√¨nh\n",
    "    model = cp_model.CpModel()\n",
    "\n",
    "    # T√≠nh th·ªùi gian t·ªëi ƒëa c√≥ th·ªÉ x·∫£y ra (ƒë·ªÉ l√†m gi·ªõi h·∫°n tr√™n cho bi·∫øn)\n",
    "    horizon = sum(task[1] for job in jobs_data for operation in job for task in operation)\n",
    "    \n",
    "    # T·∫°o bi·∫øn: (job_id, operation_id, machine_id) -> (start, duration, end)\n",
    "    task_to_interval = {}\n",
    "    task_to_machine = {}\n",
    "    for job_id in range(num_jobs):\n",
    "        for op_id in range(len(jobs_data[job_id])):\n",
    "            for task_id, (machine_id, duration) in enumerate(jobs_data[job_id][op_id]):\n",
    "                suffix = f'_j{job_id}_o{op_id}_m{machine_id}'\n",
    "                start_var = model.NewIntVar(0, horizon, 'start' + suffix)\n",
    "                end_var = model.NewIntVar(0, horizon, 'end' + suffix)\n",
    "                interval_var = model.NewIntervalVar(start_var, duration, end_var, 'interval' + suffix)\n",
    "                task_to_interval[(job_id, op_id, machine_id)] = interval_var\n",
    "                task_to_machine[(job_id, op_id, machine_id)] = machine_id\n",
    "\n",
    "    # T·∫°o bi·∫øn ƒë·ªÉ ch·ªçn m√°y cho m·ªói thao t√°c\n",
    "    machine_selection = {}\n",
    "    for job_id in range(num_jobs):\n",
    "        for op_id in range(len(jobs_data[job_id])):\n",
    "            tasks = jobs_data[job_id][op_id]\n",
    "            task_literals = []\n",
    "            for task_id, (machine_id, _) in enumerate(tasks):\n",
    "                literal = model.NewBoolVar(f'j{job_id}_o{op_id}_m{machine_id}')\n",
    "                task_literals.append(literal)\n",
    "                machine_selection[(job_id, op_id, machine_id)] = literal\n",
    "            # Ch·ªâ m·ªôt m√°y ƒë∆∞·ª£c ch·ªçn cho m·ªói thao t√°c\n",
    "            model.AddExactlyOne(task_literals)\n",
    "\n",
    "    # R√†ng bu·ªôc: C√°c thao t√°c trong c√πng m·ªôt c√¥ng vi·ªác ph·∫£i th·ª±c hi·ªán theo th·ª© t·ª±\n",
    "    for job_id in range(num_jobs):\n",
    "        for op_id in range(len(jobs_data[job_id]) - 1):\n",
    "            possible_machines_curr = jobs_data[job_id][op_id]\n",
    "            possible_machines_next = jobs_data[job_id][op_id + 1]\n",
    "            for _, (machine_curr, _) in enumerate(possible_machines_curr):\n",
    "                for _, (machine_next, _) in enumerate(possible_machines_next):\n",
    "                    curr_end = task_to_interval[(job_id, op_id, machine_curr)].EndExpr()\n",
    "                    next_start = task_to_interval[(job_id, op_id + 1, machine_next)].StartExpr()\n",
    "                    model.Add(curr_end <= next_start).OnlyEnforceIf([\n",
    "                        machine_selection[(job_id, op_id, machine_curr)],\n",
    "                        machine_selection[(job_id, op_id + 1, machine_next)]\n",
    "                    ])\n",
    "\n",
    "    # R√†ng bu·ªôc: Kh√¥ng c√≥ hai thao t√°c n√†o tr√™n c√πng m·ªôt m√°y ƒë∆∞·ª£c ch·ªìng l·∫•p\n",
    "    for machine_id in all_machines:\n",
    "        intervals = []\n",
    "        for job_id in range(num_jobs):\n",
    "            for op_id in range(len(jobs_data[job_id])):\n",
    "                for task_id, (m_id, _) in enumerate(jobs_data[job_id][op_id]):\n",
    "                    if m_id == machine_id:\n",
    "                        interval = task_to_interval[(job_id, op_id, m_id)]\n",
    "                        intervals.append(interval)\n",
    "                        model.Add(interval.StartExpr() >= 0).OnlyEnforceIf(machine_selection[(job_id, op_id, m_id)])\n",
    "        model.AddNoOverlap(intervals)\n",
    "\n",
    "    # M·ª•c ti√™u: T·ªëi thi·ªÉu h√≥a th·ªùi gian ho√†n th√†nh t·ªëi ƒëa (C_max)\n",
    "    c_max = model.NewIntVar(0, horizon, 'c_max')\n",
    "    for job_id in range(num_jobs):\n",
    "        last_op_id = len(jobs_data[job_id]) - 1\n",
    "        possible_machines = jobs_data[job_id][last_op_id]\n",
    "        for _, (machine_id, _) in enumerate(possible_machines):\n",
    "            end_time = task_to_interval[(job_id, last_op_id, machine_id)].EndExpr()\n",
    "            model.Add(c_max >= end_time).OnlyEnforceIf(machine_selection[(job_id, last_op_id, machine_id)])\n",
    "    model.Minimize(c_max)\n",
    "\n",
    "    # Gi·∫£i b√†i to√°n\n",
    "    solver = cp_model.CpSolver()\n",
    "    status = solver.Solve(model)\n",
    "\n",
    "    # In k·∫øt qu·∫£\n",
    "    if status == cp_model.OPTIMAL or status == cp_model.FEASIBLE:\n",
    "        print(f'T·ªïng th·ªùi gian ho√†n th√†nh t·ªëi ƒëa (C_max): {solver.ObjectiveValue()}')\n",
    "        print('\\nL·ªãch tr√¨nh:')\n",
    "        schedule_data = []\n",
    "        for job_id in range(num_jobs):\n",
    "            print(f'C√¥ng vi·ªác {job_id}:')\n",
    "            for op_id in range(len(jobs_data[job_id])):\n",
    "                for task_id, (machine_id, duration) in enumerate(jobs_data[job_id][op_id]):\n",
    "                    if solver.Value(machine_selection[(job_id, op_id, machine_id)]) == 1:\n",
    "                        start = solver.Value(task_to_interval[(job_id, op_id, machine_id)].StartExpr())\n",
    "                        end = solver.Value(task_to_interval[(job_id, op_id, machine_id)].EndExpr())\n",
    "                        schedule_data.append((job_id, op_id, machine_id, start, end, duration))\n",
    "                        print(f'  Thao t√°c {op_id} tr√™n m√°y {machine_id}: b·∫Øt ƒë·∫ßu {start}, k·∫øt th√∫c {end}, th·ªùi gian x·ª≠ l√Ω {duration}')\n",
    "        return schedule_data\n",
    "    else:\n",
    "        print('Kh√¥ng t√¨m th·∫•y l·ªãch tr√¨nh kh·∫£ thi.')\n",
    "        return None\n",
    "\n",
    "# Ch·∫°y ch∆∞∆°ng tr√¨nh v√† l·∫•y l·ªãch tr√¨nh\n",
    "schedule = solve_fjss()\n",
    "\n",
    "# V·∫Ω bi·ªÉu ƒë·ªì Gantt n·∫øu c√≥ l·ªãch tr√¨nh\n",
    "if schedule:\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # T·∫°o bi·ªÉu ƒë·ªì Gantt\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # M√†u s·∫Øc cho t·ª´ng c√¥ng vi·ªác\n",
    "    colors = ['#ff9999', '#66b3ff', '#99ff99']  # M√†u cho J0, J1, J2\n",
    "\n",
    "    # V·∫Ω t·ª´ng thao t√°c\n",
    "    for job_id, op_id, machine_id, start, end, duration in schedule:\n",
    "        ax.broken_barh([(start, end - start)], (machine_id - 0.4, 0.8), \n",
    "                       facecolors=colors[job_id], \n",
    "                       edgecolors='black', \n",
    "                       label=f'J{job_id}' if op_id == 0 else \"\")\n",
    "        # Th√™m nh√£n cho thao t√°c\n",
    "        ax.text(start + (end - start) / 2, machine_id, f'J{job_id}-O{op_id}', \n",
    "                ha='center', va='center',fontsize=20, color='black')\n",
    "\n",
    "    # Thi·∫øt l·∫≠p tr·ª•c\n",
    "    ax.set_ylim(-0.5, 2.5)  # 3 m√°y: M0, M1, M2\n",
    "    ax.set_xlim(0, max(end for _, _, _, _, end, _ in schedule) + 1)\n",
    "    ax.set_xlabel('Th·ªùi gian',fontsize=20, fontweight='bold')\n",
    "    ax.set_yticks(range(3))\n",
    "    ax.set_yticklabels([f'Machine {i}' for i in range(3)],fontsize=20, fontweight='bold')\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Th√™m ch√∫ th√≠ch\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), loc='upper right')\n",
    "\n",
    "    # Th√™m ti√™u ƒë·ªÅ\n",
    "\n",
    "\n",
    "    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
